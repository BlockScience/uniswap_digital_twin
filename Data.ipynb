{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b412366",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "######Global Params#######\n",
    "graph_url = 'https://api.thegraph.com/subgraphs/name/uniswap/uniswap-v2'\n",
    "\n",
    "col_data_types = {'amount0': float, 'amount1': float, 'logIndex': int, 'liquidity': float,\n",
    "                  'amount0In': float, 'amount0Out': float, 'amount1In': float, 'amount1Out': float}\n",
    "#########################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dcd7fa",
   "metadata": {},
   "source": [
    "## Query Functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3b5fd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_query(query, data_field, graph_url):\n",
    "    \"\"\"\n",
    "    Helper function to take a query and retrieve the data.\n",
    "    query (str): The query to be executed\n",
    "    data_field (str): The data field to be pulled out\n",
    "    graph_url (str): The url of the subgraph\n",
    "    \"\"\"\n",
    "    \n",
    "    #Make the request\n",
    "    request = requests.post(graph_url, json={'query': query})\n",
    "    \n",
    "    #Pull the json out from the text\n",
    "    data = json.loads(request.text)\n",
    "    \n",
    "    #Pull out the relevant data field\n",
    "    data = data['data'][data_field]\n",
    "    \n",
    "    return data\n",
    "\n",
    "def convert_where_clause(clause):\n",
    "    out = \"{\"\n",
    "    for key in clause.keys():\n",
    "        out += \"{}: \".format(key)\n",
    "        out += '\"{}\"'.format(clause[key])\n",
    "        out += \",\"\n",
    "    out += \"}\"\n",
    "    return out\n",
    "\n",
    "def query_builder(main, fields,\n",
    "                  where_clause=None, first=None, skip=None,\n",
    "                 order_by=None, order_direction=None):\n",
    "    \"\"\"\n",
    "    main (str): The main query that is being run\n",
    "    fields (list[str]): A list of strings representing each field we want to pull\n",
    "    where_clause (dict): A dictionary of clauses for filtering with the where statement\n",
    "    first (int): Number of records to grab (maximum 1000)\n",
    "    skip (int): Number of records to skip (maximum 5000)\n",
    "    order_by (str): Field to order by\n",
    "    order_direction (str): The direction of ordering for the field\n",
    "    \"\"\"\n",
    "    #Convert the where clause\n",
    "    where_clause = convert_where_clause(where_clause)\n",
    "    \n",
    "    #Clauses for the main function\n",
    "    main_clauses = []\n",
    "    if first:\n",
    "        main_clauses.append(\"first: {}\".format(first))\n",
    "    if skip:\n",
    "        main_clauses.append(\"skip: {}\".format(skip))\n",
    "    if order_by:\n",
    "        main_clauses.append(\"orderBy: {}\".format(order_by))\n",
    "    if order_direction:\n",
    "        main_clauses.append(\"orderDirection: {}\".format(order_direction))\n",
    "    if where_clause:\n",
    "        main_clauses.append(\"where: {}\".format(where_clause))\n",
    "    \n",
    "    #Convert clauses to a string\n",
    "    main_clauses = \", \".join(main_clauses)\n",
    "    \n",
    "    #Convert fields to a string\n",
    "    fields = \", \".join(fields)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    query = \"\"\"query{{\n",
    "    {}({}){{\n",
    "    {}\n",
    "    }}\n",
    "    }}\"\"\".format(main, main_clauses, fields)\n",
    "    return query\n",
    "\n",
    "def pull_data(query_function, field):\n",
    "    \"\"\"\n",
    "    Function to pull 6000 rows of data\n",
    "    \"\"\"\n",
    "    \n",
    "    #Iterate over the chunks\n",
    "    data = []\n",
    "    for i in tqdm(range(0, 6000, 1000)):\n",
    "        #Build query\n",
    "        query = query_function(i)\n",
    "        \n",
    "        #Extract data\n",
    "        data.extend(process_query(query, field, graph_url))\n",
    "        \n",
    "    #Convert to dataframe\n",
    "    data = pd.DataFrame(data)\n",
    "    data['timestamp'] = pd.to_datetime(data['timestamp'], unit = 's')\n",
    "    data['event'] = field\n",
    "    \n",
    "    #Create mapping of column data types\n",
    "    cdt = {}\n",
    "    for col in data.columns:\n",
    "        if col in col_data_types.keys():\n",
    "            cdt[col] = col_data_types[col]\n",
    "            \n",
    "    #Map the data types\n",
    "    data = data.astype(cdt)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be5a100",
   "metadata": {},
   "source": [
    "## Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bf91bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:02<00:00,  2.40it/s]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.35it/s]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.89it/s]\n"
     ]
    }
   ],
   "source": [
    "mint_query = lambda i: query_builder(\"mints\",\n",
    "                  [\"timestamp\", \"amount0\", \"amount1\", \"logIndex\", \"liquidity\"],\n",
    "                 first=1000, skip=i, order_by=\"timestamp\", order_direction=\"desc\",\n",
    "                         where_clause={\"pair\": \"0xa478c2975ab1ea89e8196811f51a7b7ade33eb11\"})\n",
    "\n",
    "burns_query = lambda i: query_builder(\"burns\",\n",
    "                  [\"timestamp\", \"amount0\", \"amount1\", \"logIndex\", \"liquidity\"],\n",
    "                 first=1000, skip=i, order_by=\"timestamp\", order_direction=\"desc\",\n",
    "                         where_clause={\"pair\": \"0xa478c2975ab1ea89e8196811f51a7b7ade33eb11\"})\n",
    "\n",
    "swaps_query = lambda i: query_builder(\"swaps\",\n",
    "                  [\"timestamp\", \"amount0In\", \"amount1In\", \"amount0Out\", \"amount1Out\",\"logIndex\"],\n",
    "                 first=1000, skip=i, order_by=\"timestamp\", order_direction=\"desc\",\n",
    "                         where_clause={\"pair\": \"0xa478c2975ab1ea89e8196811f51a7b7ade33eb11\"})\n",
    "\n",
    "queries = [mint_query, burns_query, swaps_query]\n",
    "fields = [\"mints\", \"burns\", \"swaps\"]\n",
    "data = [pull_data(q, f) for q, f in zip(queries, fields)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4756e442",
   "metadata": {},
   "source": [
    "## Processing Functions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4842bac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_data_overlap(data):\n",
    "    \"\"\"\n",
    "    Function to find the earliest date that ensures data overlap.\n",
    "    \"\"\"\n",
    "    return max([df['timestamp'].min() for df in data])\n",
    "\n",
    "def process_amount(df):\n",
    "    if df['event'].iloc[0] == 'mints':\n",
    "        pass\n",
    "    elif df['event'].iloc[0] == 'burns':\n",
    "        df[['amount0', 'amount1', 'liquidity']] *= -1\n",
    "    elif df['event'].iloc[0] == 'swaps':\n",
    "        df['amount0'] = df['amount0Out'] - df['amount0In']\n",
    "        df['amount1'] = df['amount1Out'] - df['amount1In']\n",
    "        df['liquidity'] = 0\n",
    "        df.drop(columns=['amount0Out', 'amount0In', 'amount1Out', 'amount1In'], inplace=True)\n",
    "        \n",
    "def process_events(df):\n",
    "    if df['event'].iloc[0] == 'mints':\n",
    "        df['event'] = 'mint'\n",
    "    elif df['event'].iloc[0] == 'burns':\n",
    "        df['event'] = 'burn'\n",
    "    elif df['event'].iloc[0] == 'swaps':\n",
    "        df['event'] = (df['amount0'] > 0).map({True: 'ethPurchase', False: 'tokenPurchase'})\n",
    "\n",
    "def process_data(data, lim_date=False):\n",
    "    #Do all data processing\n",
    "    for df in data:\n",
    "        process_amount(df)\n",
    "        process_events(df)\n",
    "    \n",
    "    #Consider only overlapping data\n",
    "    if lim_date:\n",
    "        overlap_date = find_data_overlap(data)\n",
    "        data = [df[df['timestamp'] >= overlap_date] for df in data]\n",
    "    \n",
    "    #Concat\n",
    "    data = pd.concat(data)\n",
    "    \n",
    "    #Rename columns\n",
    "    data = data.rename(columns={'amount0': 'token_delta', 'amount1': 'eth_delta', 'liquidity': 'UNI_delta'})\n",
    "    \n",
    "    #Indexing\n",
    "    data = data.sort_values(['timestamp', 'logIndex'])\n",
    "    data.reset_index(inplace = True, drop = True)\n",
    "    \n",
    "    #Find balances over time\n",
    "    for col1, col2 in zip(['token_balance', 'eth_balance', 'UNI_supply'], ['token_delta', 'eth_delta', 'UNI_delta']):\n",
    "        data[col1] = data[col2].cumsum()\n",
    "    \n",
    "    print(\"TODO: ADD IN GENESIS STATE\")\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0ead0a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TODO: ADD IN GENESIS STATE\n"
     ]
    }
   ],
   "source": [
    "data = process_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8514f58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        token_delta  eth_delta   UNI_delta  logIndex           timestamp  \\\n",
      "0         42.013254   0.089123    1.627649       212 2020-11-18 19:40:10   \n",
      "1         52.962480   0.112554    2.053689       356 2020-11-18 19:58:48   \n",
      "2       5000.000000  10.625789  193.881475        73 2020-11-18 19:58:57   \n",
      "3        272.418088   0.579633   10.569748       138 2020-11-18 20:23:39   \n",
      "4         37.464296   0.079796    1.454344       155 2020-11-18 20:39:06   \n",
      "...             ...        ...         ...       ...                 ...   \n",
      "17995  22543.918424 -11.384998    0.000000       159 2021-07-13 18:04:29   \n",
      "17996 -41813.000000  20.978218    0.000000        12 2021-07-13 18:04:54   \n",
      "17997  48706.517542 -24.588929    0.000000        16 2021-07-13 18:04:54   \n",
      "17998    -20.000000   0.010050    0.000000       243 2021-07-13 18:08:20   \n",
      "17999  60522.924708 -30.650000    0.000000       111 2021-07-13 18:09:39   \n",
      "\n",
      "               event  token_balance  eth_balance     UNI_supply  \n",
      "0               mint   4.201325e+01     0.089123       1.627649  \n",
      "1               mint   9.497573e+01     0.201677       3.681338  \n",
      "2               mint   5.094976e+03    10.827466     197.562813  \n",
      "3               mint   5.367394e+03    11.407099     208.132561  \n",
      "4               mint   5.404858e+03    11.486895     209.586905  \n",
      "...              ...            ...          ...            ...  \n",
      "17995    ethPurchase  -6.342279e+07 -5628.639509 -664548.806640  \n",
      "17996  tokenPurchase  -6.346460e+07 -5607.661291 -664548.806640  \n",
      "17997    ethPurchase  -6.341590e+07 -5632.250221 -664548.806640  \n",
      "17998  tokenPurchase  -6.341592e+07 -5632.240170 -664548.806640  \n",
      "17999    ethPurchase  -6.335539e+07 -5662.890170 -664548.806640  \n",
      "\n",
      "[18000 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095ccdcb",
   "metadata": {},
   "source": [
    "### To Do:\n",
    "\n",
    "1. Genesis state methodology.\n",
    "2. Overlapping data choice\n",
    "3. Extension to running based on time/days to get longer history?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07971a8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
